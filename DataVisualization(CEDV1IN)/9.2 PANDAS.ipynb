{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b678f1c3",
   "metadata": {},
   "source": [
    "# 9.2 PANDAS  #Saikiran Dasari  IBM (DV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2130d",
   "metadata": {},
   "source": [
    ">**What are pandas?**\n",
    "\n",
    "Pandas is an open-source Python Library providing high-performance data manipulation and analysis tool using its powerful data structures. Pandas is the backbone for most of the data projects.\n",
    "\n",
    "Through pandas, you get acquainted with your data by cleaning, transforming, and analyzing it. Python with Pandas is used in a wide range of fields including academic and commercial domains including finance, economics, Statistics, analytics, etc.\n",
    "\n",
    "We can import the library or a dependency like pandas using the “import pandas” command. We now have access to many pre-built classes and functions.\n",
    "\n",
    "In order to be able to work with the data in Python, we’ll need to read the data(csv, excel ,dictionary,..) file into a Pandas DataFrame. \n",
    "\n",
    " A DataFrame is a way to represent and work with tabular data. Tabular data has rows and columns, just like our csv file. In order to read in the data, we’ll need to use the pandas.read_csv function. This function will take in a csv file and return a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b3797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d8efcf",
   "metadata": {},
   "source": [
    "## Next Slide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce468c",
   "metadata": {},
   "source": [
    ">**What is csv?**\n",
    "\n",
    "csv stands for comma-separated values, csv file is a delimited text file that uses a comma to separate values. A CSV file stores tabular data in plain text. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\n",
    "\n",
    "\n",
    "\n",
    ">**How to read the csv file using pandas?**\n",
    "\n",
    "Once the pandas library is imported, This assumes the library is installed. Then we can load a csv file using the pandas built-in function “read csv.” A csv is a typical file type used to store data.\n",
    "\n",
    "We simply type the word pandas, then a dot and the name of the function with all the inputs. Typing pandas all the time may get tedious.\n",
    "\n",
    "We can use the \"as\" statement to shorten the name of the library; in this case we use the standard abbreviation pd. Now we type pd and a dot followed by the name of the function we would like to use, in this case, read_csv.\n",
    " \n",
    "we need to give the path of the csv file as argument to the read_csv function, to read the path string correctly we need to use ‘r’ as a prefix to the command. \n",
    "\n",
    "The result is stored in the variable df. this is short for “dataframe.\" Now that we have the data in a dataframe, we can work with it.\n",
    "\n",
    "We can use the method head to see the entire data frame or we can pass the number of rows to be checked as an argument to the head method like df.head(5) for 5 rows.\n",
    "\n",
    "\n",
    ">**How to Write the csv file using pandas?**\n",
    "\n",
    "If you want to write the dataframe to csv we can simple use the “to_csv” function\n",
    "\n",
    "Syntax:\n",
    "df.to_csv(EXPORT FILE PATH)\n",
    "\n",
    ">>**example:**\n",
    "If you see the above data frame example we see the two indexes one is loaded from the csv file and also there is unnamed index which is by default generated by pandas while loading the csv.\n",
    "\n",
    "This problem can be avoided by making sure that the writing of CSV files\n",
    "doesn’t write indexes, because DataFrame will generate it anyway. \n",
    "\n",
    "We can do the same by specifying index = False parameter in to_csv(...) function.\n",
    "\n",
    "df.to_csv(‘EXPORT FILE PATH’, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafed9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b4268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c600c3de",
   "metadata": {},
   "source": [
    "## Next Slide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddecf8e",
   "metadata": {},
   "source": [
    "## Pandas working with text data and datetime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148a280",
   "metadata": {},
   "source": [
    "**DateTime for TimeSeries Data**\n",
    "\n",
    "While working with data, it is not an unusual thing to encounter time series data. Working with datetime columns can be quite challenge task. Luckily, pandas are great at handling time series data. Pandas provide a different set of tools using which we can perform all the necessary tasks on date-time data.\n",
    "\n",
    "Let’s see how we can convert a dataframe column of strings (in dd/mm/yyyy format) to datetime format. We cannot perform any time series-based operation on the dates if they are not in the right format. To be able to work with it, we are required to convert the dates into the datetime format.\n",
    "\n",
    "\n",
    "**Convert Pandas dataframe column type from string to datetime format**\n",
    "\n",
    "For any operation we need to first create the data frame based on the data collected, we can load the data either from csv file, or excel file or from any source. Let us use csv file for our demo.\n",
    "\n",
    "Follow the below lines of code to load the data and convert that to data Frame.\n",
    "\n",
    "Once the data frame is ready use df.info( ) to get complete information of dataframe.\n",
    "\n",
    "As we can see in the output, the data type of the ‘DateTime’ column is object i.e. string. Now we will convert it to datetime format using pd.to_datetime() function.\n",
    "\n",
    "\n",
    "After applying the pd.to_datetime () function to DateTime column, we can see in the output, the format of the ‘DateTime’ column has been changed to the datetime format.\n",
    "\n",
    "\n",
    "**HOW TO CHANGE THE INDEX of the dataframe**\n",
    "\n",
    "Most of the operations related to dateTime requires the DateTime column as the primary index, or else it will throw an error.\n",
    "\n",
    "We can change the index with set_index() function.it takes two parameters one is column name you want to change as index, and another one is inplace=true. When inplace=True is passed, the data is renamed inplace, when inplace=False is passed (this is the default value, so isn't necessary), performs the operation and returns a copy of the object.\n",
    "\n",
    "\n",
    "**Data Frame Filtering based on index**\n",
    "\n",
    "How to filter data based on particular year?\n",
    "To Check all the values occurred in a particular year let’s say 2018\n",
    "\n",
    "Run command df[‘2018’]\n",
    "\n",
    "\n",
    "\n",
    "**How to filter data based on year and month?**\n",
    "\n",
    "To View all observations that occurred in June 2018, run the below command\n",
    "df['2018-06']\n",
    "\n",
    "\n",
    "**Similarly, if you want to view the observations after particular year, month and date. then the command is**\n",
    "\n",
    "df[datetime(year, month, date): ]\n",
    "\n",
    "\n",
    "**If you need observations between two dates then command is?**\n",
    "df['Starting_year, Starting_month, Starting_date':'Ending_year, Ending_month, Ending_date']\n",
    "\n",
    "For ex: If you need Observations betn May 3rd & May 4th of 2018 then command is:\n",
    "\n",
    "df['5/3/2018':'5/4/2018']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d932e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeb4a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e7caef3",
   "metadata": {},
   "source": [
    "## Next Slide:\n",
    "### Pandas Indexing and Selecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6338fe",
   "metadata": {},
   "source": [
    "What is Indexing?\n",
    "\n",
    "Indexing in pandas means simply selecting particular rows and columns of data from a DataFrame. Indexing could mean selecting  all the rows and some of the columns, some of the rows and all the columns, or some of each of the rows and columns. Indexing can also be known as Subset Selection.\n",
    "\n",
    "Let’s load one csv file and convert that to data frame to perform the indexing and selection operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3349d7",
   "metadata": {},
   "source": [
    "Once the data is loaded into data frame let’s make Name as the index of this data frame.\n",
    "\n",
    "**Note: INDEX is the Primary key it should Not Contain Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f927a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edbc9cf3",
   "metadata": {},
   "source": [
    "**Making the Index for ColumnName(as this has UNIQUE records!)**\n",
    "\n",
    "df.set_index('ColumnName',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269bcd2",
   "metadata": {},
   "source": [
    "**Once the data is loaded into data frame let’s Revert df as the index of this data frame.**\n",
    "\n",
    "We use “.reset_index(inplace=True)\n",
    "\n",
    "df.reset_index(inplace=True)  //To revert back the Index column!\n",
    "\n",
    "**Selecting Single Column**\n",
    "\n",
    "In order to take single column, we simply put the name of the column in-between the brackets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = sales_data_2017['Model']\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d11515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6050ce49",
   "metadata": {},
   "source": [
    "**Selecting Multiple Columns**\n",
    "\n",
    "To select multiple columns, we must pass a list of columns in an indexing operator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2514dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelandRegion = sales_data_2017[['Model', 'Region']]\n",
    "ModelandRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b5eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd76e01",
   "metadata": {},
   "source": [
    "**Selecting a single row:**\n",
    "    \n",
    "In order to select a single row using. loc[], we put a single row label in a .loc function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46630b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "December31st = sales_data_2017.loc['2017-12-31']\n",
    "December31st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3843713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0cbb26f",
   "metadata": {},
   "source": [
    "**Selecting multiple rows:**\n",
    "\n",
    "In order to select multiple rows, we put all the row labels in a list and pass that to .loc function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11333d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HiHello = sales_data_2017.loc[['hi','hello']]\n",
    "HiHello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2e49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa09f88c",
   "metadata": {},
   "source": [
    "**Selecting multiple rows and columns:**\n",
    "\n",
    "In order to select two rows and two columns, we select two rows which we want to select and two columns and put it in a separate list:\n",
    "Dataframe.loc[[\"row1\", \"row2\"], [\"column1\", \"column2\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d0d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "HiHelloRegionModel = sales_data_2017.loc[['hi','hello'], ['Region','Model']]\n",
    "HiHelloRegionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffda8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8e26e4e",
   "metadata": {},
   "source": [
    "**In order to select all the rows and some columns the syntax looks like:**\n",
    "\n",
    "Dataframe.loc [ :, [\"column1\", \"column2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed70c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegionModel = sales_data_2017.loc[ : , ['Region','Model']]\n",
    "RegionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c0501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0381cd9d",
   "metadata": {},
   "source": [
    "## Next Slide:\n",
    "## Pandas- groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1a2b2",
   "metadata": {},
   "source": [
    "**What is Pandas-GroupBy?**\n",
    "\n",
    "A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups.\n",
    "\n",
    "Let’s load one csv file and convert that to data frame to perform the group-by operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8af130",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_2017.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd0665",
   "metadata": {},
   "source": [
    "groupby function based on single category\n",
    "\n",
    "Now we have data frame ready let’s group the data based on ‘hlpi_name’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO this First for whichever column you want to go ahead for Grop analysis\n",
    "groups = sales_data_2017.groupby('Region')\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a1e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9833365",
   "metadata": {},
   "source": [
    "Once group by operation is done we get a result as groupby object.\n",
    "\n",
    "Let’s print the value contained in any one of group. For that use the name of the ‘Region’. We use the function get_group() to find the entries contained in any of the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To know all the Unique values(groups) in Region column!\n",
    "sales_data_2017['Region'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee002ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_group() function\n",
    "# To get values contained in any one of Group\n",
    "groups.get_group('United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a7afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79d7c544",
   "metadata": {},
   "source": [
    "**groupby function based on more than one category**\n",
    "\n",
    "Use groupby() function to form groups based on more than one category (i.e. Use more than one column to perform the splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_2 = sales_data_2017.groupby(['Region', 'Category'])\n",
    "group_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd4a892",
   "metadata": {},
   "source": [
    "We got the result as groupby object.\n",
    "\n",
    "Let’s print the first entries in all the groups formed using first() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde38ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first() Function\n",
    "group_2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a239e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "407d5846",
   "metadata": {},
   "source": [
    "**Operations on groups**\n",
    "\n",
    "After splitting a data into a group, we can also apply a function to each group to perform some operations.\n",
    "\n",
    "Here is the Sample example to get sum of values in particular groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum() function\n",
    "## WE get the Result for Numerical Columns!\n",
    "GroupBySum = sales_data_2017.groupby(['Region'])\n",
    "GroupBySum.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651a1264",
   "metadata": {},
   "source": [
    "**We can also find min, max, average . .etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max()\n",
    "GroupBySum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe830dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min()\n",
    "GroupBySum.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a21f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27d49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2460a390",
   "metadata": {},
   "source": [
    "## Next Slide:\n",
    "## Merge/Join Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e52608",
   "metadata": {},
   "source": [
    "Joining and merging DataFrames is the core process to start with Data Analysis and Machine Learning tasks. \n",
    "It is one of the toolkits which every Data Analyst or Data Scientist should master because in almost all the cases data comes from multiple source and files. \n",
    "\n",
    "You may need to bring all the data in one place by some sort of join logic and then start your analysis. \n",
    "Thankfully you have the most popular library in python, pandas to your rescue! \n",
    "Pandas provides various facilities for easily combining different datasets.\n",
    "\n",
    "We can merge two data frames in pandas python by using the merge() function. \n",
    "\n",
    "The different arguments to merge() allow you to perform natural join, left join, right join, and full outer join in pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d10d2",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaa51a7",
   "metadata": {},
   "source": [
    "Understanding the different types of merge:\n",
    "\n",
    "Before you perform joint operations let’s first load the two csv files and convert them into data frames df1 and df2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280b6c2",
   "metadata": {},
   "source": [
    "## https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/\n",
    "Method #3: Creating DataFrame from dict of narray/lists\n",
    "To create DataFrame from dict of narray/list, all the narray must be of same length. \n",
    "If index is passed then the length index should be equal to the length of arrays. \n",
    "If no index is passed, then by default, index will be range(n) where n is the array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cb07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Washing Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Washing Machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Washing Machine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id          Product\n",
       "0            1             Oven\n",
       "1            2       Television\n",
       "2            3               AC\n",
       "3            4  Washing Machine\n",
       "4            5               AC\n",
       "5            6             Oven\n",
       "6            7       Television\n",
       "7            8  Washing Machine\n",
       "8            9       Television\n",
       "9           10  Washing Machine"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python code demonstrate creating\n",
    "# DataFrame from dict narray / lists\n",
    "# By default addresses.\n",
    "  \n",
    "import pandas as pd\n",
    "  \n",
    "# initialize data of lists.\n",
    "df1 = {'customer_id': [1,2,3,4,5,6,7,8,9,10],\n",
    "        'Product': ['Oven','Television','AC','Washing Machine','AC','Oven',\n",
    "                    'Television','Washing Machine','Television','Washing Machine']}\n",
    "  \n",
    "# Create DataFrame\n",
    "df1 = pd.DataFrame(df1)\n",
    "  \n",
    "# Print the output.\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009e8a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is 2A45-41DC\n",
      "\n",
      " Directory of C:\\Users\\Sai\\Desktop\\New folder\\IBM Exam\\DataVisualizations\n",
      "\n",
      "2022-09-19  20:02    <DIR>          .\n",
      "2022-09-17  20:29    <DIR>          ..\n",
      "2022-09-19  19:23    <DIR>          .ipynb_checkpoints\n",
      "2022-09-08  13:15           108,604 1_DataVisualizations.docx\n",
      "2022-09-19  19:48           233,658 10_1 Matplotlib.ipynb\n",
      "2022-09-19  19:21         1,037,547 10_Matplotlib.docx\n",
      "2022-09-19  20:02            60,303 11_BasicPlotsMatplotlib(AreaBarHistogram).ipynb\n",
      "2022-09-08  15:05           428,703 2_InferentialStats.docx\n",
      "2022-09-08  16:42         4,081,073 3_InstallationOfR.docx\n",
      "2022-09-08  16:54           769,422 4_DescriptiveDAusingR.docx\n",
      "2022-09-09  19:26         2,334,409 5_DataManipulationWithR.docx\n",
      "2022-09-10  21:18           583,007 6_WorikingWithRgraphics(ScatterPlot, BarPlot, Histogram).docx\n",
      "2022-09-10  22:08         1,704,153 7_DVonWatsonStudio.docx\n",
      "2022-09-16  12:05         2,724,652 8_AnacondaJupyterNBpythonCodes.docx\n",
      "2022-09-16  23:46             9,374 9.1 NUMPY.ipynb\n",
      "2022-09-17  08:17            47,899 9.2 PANDAS.ipynb\n",
      "2022-09-16  23:57         1,993,813 9_Numpy&Pandas.docx\n",
      "2022-09-18  20:51           390,524 Canada_Matplotlib.xlsx\n",
      "2022-09-19  16:53            44,384 CanadianImmigrants.xlsx\n",
      "2022-09-17  08:17            71,002 Chapter 8 Introduction to Python.ipynb\n",
      "2022-09-09  19:29    <DIR>          R_Coding\n",
      "              17 File(s)     16,622,527 bytes\n",
      "               4 Dir(s)  57,066,070,016 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30657637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id       state\n",
       "0            1       Texas\n",
       "1            2  California\n",
       "2            4     Florida\n",
       "3            7  California\n",
       "4           10     Florida"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize data of lists.\n",
    "df2 = {'customer_id': [1,2,4,7,10],\n",
    "        'state': ['Texas','California','Florida','California','Florida']}\n",
    "  \n",
    "# Create DataFrame\n",
    "df2 = pd.DataFrame(df2)\n",
    "  \n",
    "# Print the output.\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87363cd",
   "metadata": {},
   "source": [
    "### 1) Natural join\n",
    "\n",
    "Natural join keeps only rows that match from the data frames(df1 and df2), specify the argument how=’inner’\n",
    "\n",
    "Syntax:\n",
    "\n",
    "pd.merge(df1, df2, on=column', how='inner')\n",
    "Return only the rows in which the left table have matching keys in the right table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8004e911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Product</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oven</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id          Product       state\n",
       "0            1             Oven       Texas\n",
       "1            2       Television  California\n",
       "2            4  Washing Machine     Florida\n",
       "3            7       Television  California\n",
       "4           10  Washing Machine     Florida"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on = 'customer_id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694290d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2256689a",
   "metadata": {},
   "source": [
    "### 2) Full outer join\n",
    "\n",
    "Full outer join keeps all rows from both data frames, specify how=‘outer’.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "pd.merge(df1, df2, on=column', how=’outer’)\n",
    "Returns all rows from both tables, join records from the left which have matching keys in the right table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112e14e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Product</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oven</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Oven</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Television</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id          Product       state\n",
       "0            1             Oven       Texas\n",
       "1            2       Television  California\n",
       "2            3               AC         NaN\n",
       "3            4  Washing Machine     Florida\n",
       "4            5               AC         NaN\n",
       "5            6             Oven         NaN\n",
       "6            7       Television  California\n",
       "7            8  Washing Machine         NaN\n",
       "8            9       Television         NaN\n",
       "9           10  Washing Machine     Florida"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on = 'customer_id', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47deaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4887361d",
   "metadata": {},
   "source": [
    "### 3) Left outer join\n",
    "\n",
    "Left outer join includes all the rows of your data frame df1 and only those from df2 that match, specify how =‘Left.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "pd.merge(df1, df2, on=column', how=left)\n",
    "Return all rows from the left table, and any rows with matching keys from the right table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90f5df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Product</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oven</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Oven</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Television</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id          Product       state\n",
       "0            1             Oven       Texas\n",
       "1            2       Television  California\n",
       "2            3               AC         NaN\n",
       "3            4  Washing Machine     Florida\n",
       "4            5               AC         NaN\n",
       "5            6             Oven         NaN\n",
       "6            7       Television  California\n",
       "7            8  Washing Machine         NaN\n",
       "8            9       Television         NaN\n",
       "9           10  Washing Machine     Florida"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58878486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fefaf5a",
   "metadata": {},
   "source": [
    "### 4) Right outer join\n",
    "\n",
    "Return all rows from the df2 table, and any rows with matching keys from the df1 table, specify how =‘Right’.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "pd.merge(df1, df2, on=column', how=right)\n",
    "Return all rows from the right table, and any rows with matching keys from the left table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9fea517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>Product</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oven</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Washing Machine</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id          Product       state\n",
       "0            1             Oven       Texas\n",
       "1            2       Television  California\n",
       "2            4  Washing Machine     Florida\n",
       "3            7       Television  California\n",
       "4           10  Washing Machine     Florida"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, on = 'customer_id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dd430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1673bf75",
   "metadata": {},
   "source": [
    "# DELIVERABLES !\n",
    "### through this SECTION for PANDAS!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72973abb",
   "metadata": {},
   "source": [
    "**Pandas read and write csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e67fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to read the csv file using pandas?\n",
    "df = pd.read_csv(r\"C:\\Users\\.......\")\n",
    "## need to give the path of the csv file as argument to the read_csv function, to read the path string correctly we need to use ‘r’ as a prefix to the command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ac1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##How to Write the csv file using pandas?\n",
    "df.to_csv(‘EXPORT FILE PATH’, index=False) #specifying index = False parameter in to_csv(...) function -> It doesn’t write indexes, because DataFrame will generate it anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758dff4c",
   "metadata": {},
   "source": [
    "**Descriptive statistics using “PANDAS”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "These are the three steps we should perform to do statistical analysis on pandas dataframe.\n",
    "•\tcollect the data\n",
    "•\tcreate the data frame\n",
    "•\tget the descriptive statistics for pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27028f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You Can Further Drill the Stats for each Columns Specific!\n",
    "df['Sell'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126bdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1c610c",
   "metadata": {},
   "source": [
    "**Pandas working with text data and datetime columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd749e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the data type of the ‘DateTime’ column is object i.e. string. Now we will convert it to datetime format using pd.to_datetime() function.\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "## After applying the pd.to_datetime () function to DateTime column, we can see in the output, the format of the ‘DateTime’ column has been changed to the datetime format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d50dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can change the index with set_index() function.it takes two parameters one is column name you want to change as index, and another one is inplace=true. \n",
    "df.set_index('DateTime', inplace=True)\n",
    "## Now the DateTime is the index of the dataframe. Now we can perform DateTime operations very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame Filtering based on index\n",
    "## How to filter data based on particular year?\n",
    "df['2010']\n",
    "\n",
    "## How to filter data based on year and month?\n",
    "df['2018-06']\n",
    "\n",
    "## Similarly, if you want to view the observations after particular year, month and date. then the command is\n",
    "df[datetime(year, month, date): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4170b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you need observations between two dates then command is?\n",
    "\n",
    "##SYNTAX: \n",
    "##df['StartingYear, StartingMonth, StartingDate' : 'EndingYear, EndingMonth, Endingdate']\n",
    "\n",
    "##Command:\n",
    "df['5/3/2018' : '5/4/2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091416f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Que) What is the syntax to change the index of the dataframe with out returning the copy of the object\n",
    "## df.setindex(‘column name’, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204ebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c6fbe29",
   "metadata": {},
   "source": [
    "**Pandas Indexing and Selecting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Once the data is loaded into data frame let’s make Name Column as the index of this data frame.\n",
    "df.set_index(\"Name\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the data is loaded into data frame let’s Revert df as the index of this data frame.  \n",
    "## We use “.reset_index(inplace=True)\n",
    "\n",
    "df.reset_index(inplace=True)  #To revert back the Index column!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43adf590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Single Column\n",
    "## In order to take single column, we simply put the name of the column in-between the brackets.\n",
    "Email = df['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252a0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Multiple Columns\n",
    "## To select multiple columns, we must pass a list of columns in an indexing operator.\n",
    "\n",
    "emailANDteam = df[[\"email\", \"team\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single row:\n",
    "## In order to select a single row using. loc[], we put a single row label in a .loc function.\n",
    "LucyData = df.loc['Lucy']\n",
    "\n",
    "\n",
    "# Selecting multiple rows:\n",
    "## In order to select multiple rows, we put all the row labels in a list and pass that to .loc function.\n",
    "jesseANDeric = df.loc[['Jesse', 'Eric']]\n",
    "\n",
    "\n",
    "# Selecting multiple rows and columns:\n",
    "## In order to select two rows and two columns, we select two rows which we want to select and two columns and put it in a separate list:\n",
    "## SYNTAX: Dataframe.loc[[\"row1\", \"row2\"], [\"column1\", \"column2\"]]\n",
    "selectedDF = df.loc[['Judith', 'Arlene'], ['email', 'team']]\n",
    "\n",
    "\n",
    "# In order to select all the rows and some columns the syntax looks like:\n",
    "## SYNTAX: Dataframe.loc [ :, [\"column1\", \"column2\"]]\n",
    "selectedDF = df.loc[ : ,['email', 'team']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49771a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23f9b256",
   "metadata": {},
   "source": [
    "**Pandas- GROUPBY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ae3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby function based on single category\n",
    "## Now we have data frame ready let’s group the data based on ‘hlpi_name’.\n",
    "groups = df.groupby('hlpi_name')\n",
    "\n",
    "## To know all the Unique values(GROUPS) in above hlpi_name colums use: drop.duplicates()\n",
    "df['hpli_name'].drop.duplicates()\n",
    "\n",
    "## We use the function get_group() to find the entries contained in any of the groups.\n",
    "groups.get_group('Income quintile 1 (low)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d67cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby function based on more than one category\n",
    "## Use groupby() function to form groups based on more than one category (i.e. Use more than one column to perform the splitting).\n",
    "group_2 = df.groupby(['hlpi_name', 'year'])\n",
    "\n",
    "\n",
    "## Let’s print the first entries in all the groups formed using first() function.\n",
    "group_2 = df.groupby(['hlpi_name', 'year'])\n",
    "group_2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations on groups\n",
    "## After splitting a data into a group, we can also apply a function to each group to perform some operations\n",
    "\n",
    "# sum() function\n",
    "## WE get the Result for Numerical Columns!\n",
    "Group = df.groupby(['hlpi_name'])\n",
    "Group.sum()\n",
    "\n",
    "# We can also find min, max, average . .etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d132c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846c73fc",
   "metadata": {},
   "source": [
    "**Merge/Join Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you perform joint operations let’s first load the two csv files and convert them into data frames df1 and df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac58cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURAL JOIN\n",
    "## Natural join keeps only rows that match from the data frames (df1 and df2), specify the argument how=’inner’\n",
    "\n",
    "pd.merge(df1, df2, on = 'customer_id', how = 'inner')\n",
    "## Return only the rows in which the left table have matching keys in the right table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c812c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL OUTER JOIN\n",
    "## Full outer join keeps all rows from both data frames, specify how=‘outer’.\n",
    "\n",
    "pd.merge(df1, df2, on = 'customer_id', how = 'outer')\n",
    "## The join which keeps all the rows that match from both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636842d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT OUTER JOIN\n",
    "## Left outer join includes all the rows of your data frame df1 and only those from df2 that match, specify how =‘Left.\n",
    "\n",
    "pd.merge(df1, df2, on = 'customer_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ee311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIGHT OUTER Join\n",
    "## Return all rows from the df2 table, and any rows with matching keys from the df1 table, specify how =‘Right’.\n",
    "\n",
    "pd.merge(df1, df2, on = 'customer_id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ffbd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "910be6cb",
   "metadata": {},
   "source": [
    "# QNA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18a954",
   "metadata": {},
   "source": [
    "https://quizizz.com/admin/quiz/5e952fd57487f7001bcbe21f/pandas-python-quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061883cc",
   "metadata": {},
   "source": [
    "**Q. Which of the following can be used to make a Dataframe?**\n",
    "\n",
    "Series\n",
    "\n",
    "DataFrame\n",
    "\n",
    "Structured ndarray\n",
    "\n",
    "**All of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20d665",
   "metadata": {},
   "source": [
    "**Q.What can help to form dictionary constructor’s form?**\n",
    "\n",
    "DataFrame.from_dict\n",
    "\n",
    "DataFrame.from_items\n",
    "\n",
    "**DataFrame.from_records**\n",
    "\n",
    "All of the mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1d328",
   "metadata": {},
   "source": [
    "**Q.Identify the correct statement:**\n",
    "\n",
    "Moving window statistics is present in pandas.\n",
    "\n",
    "Pandas have a set of array data structures which are labelled.\n",
    "\n",
    "Pandas consists of an integrated group by engine for transforming and aggregating data sets.\n",
    "\n",
    "**All of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed06d1",
   "metadata": {},
   "source": [
    "**Q.If the data is in the form of an ndarray, the index and the data must be of the same length.**\n",
    "\n",
    "**True**\n",
    "\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971b51f7",
   "metadata": {},
   "source": [
    "**Q.Data structures in Pandas can be mutated in the terms of ____ but not of _____.**\n",
    "\n",
    "size, value\n",
    "\n",
    "**value, size**\n",
    "\n",
    "semantic, size\n",
    "\n",
    "none of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c7559",
   "metadata": {},
   "source": [
    "**Q.Among the following options, which operation works with a syntax same as that of the analogous dictionary operations?**\n",
    "\n",
    "Deleting columns\n",
    "\n",
    "Setting columns\n",
    "\n",
    "Getting columns\n",
    "\n",
    "**All of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ed4c6",
   "metadata": {},
   "source": [
    "**Q.Point out the statement which is incorrect:**\n",
    "\n",
    "**Panel is generally a 2D array which is labelled and also size-mutable.**\n",
    "\n",
    "Series is a 1D array which is labelled and homogeneously typed.\n",
    "\n",
    "DataFrame is generally a 2D structure which is labelled, tabular and size-mutable with columns that can potentially be heterogeneously typed.\n",
    "\n",
    "None of the mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95e05f",
   "metadata": {},
   "source": [
    "**Q.Are DataFrames container for Series.**\n",
    "\n",
    "**True**\n",
    "\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797a18e",
   "metadata": {},
   "source": [
    "**Q. The power of Pandas is brought to the physical sciences by x-ray.**\n",
    "\n",
    "**True**\n",
    "\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00baf78",
   "metadata": {},
   "source": [
    "**Q. Which among the following statements are true with respect to the Series and DataFrames in Pandas?**\n",
    "\n",
    "**The 2 key structures in Pandas are Series and DataFrames.**\n",
    "\n",
    "For Pandas, the core data model is Series, while the secondary model is DataFrame.\n",
    "\n",
    "The DataFrame is like an Excel workbook.\n",
    "\n",
    "Accessing individual elements is not allowed in Series through labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05d2850",
   "metadata": {},
   "source": [
    "**Q. This function in the library of Pandas allows you to manipulate data and create new variables:**\n",
    "\n",
    "answer choices\n",
    "read_csv function\n",
    "\n",
    "pivot_table function\n",
    "\n",
    "**apply function**\n",
    "\n",
    "merge function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6705d",
   "metadata": {},
   "source": [
    "**Q.Which of these is an invalid writer function in Pandas?**\n",
    "\n",
    "to_clipboard\n",
    "\n",
    "**to_text**\n",
    "\n",
    "to_stata\n",
    "\n",
    "to_msgpack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43a8c2",
   "metadata": {},
   "source": [
    "**Q. Which among the following options can be used to create a DataFrame in Pandas?**\n",
    "\n",
    "A scalar value\n",
    "\n",
    "An ndarray\n",
    "\n",
    "A python dict\n",
    "\n",
    "**All of the above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638f81c",
   "metadata": {},
   "source": [
    "**Q. Identify the correct statement:**\n",
    "    \n",
    "The standard marker for missing data in Pandas is NaN\n",
    "\n",
    "Series act in a way similar to that of an array\n",
    "\n",
    "**Both of the above**\n",
    "\n",
    "None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b297ce9",
   "metadata": {},
   "source": [
    "**Q.What happens to the indexes when any operations are done to unaligned series?**\n",
    "\n",
    "Total\n",
    "\n",
    "**Union**\n",
    "\n",
    "Intersection\n",
    "\n",
    "All of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740c386",
   "metadata": {},
   "source": [
    "**Q. A series is a one-dimensional array which is labelled and can hold any data type.**\n",
    "\n",
    "**True**\n",
    "\n",
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b0701",
   "metadata": {},
   "source": [
    "**Q. Point out the incorrect statement:**\n",
    "\n",
    "Both Series and ndarrays can be passed as arguments to Numpy functions.\n",
    "\n",
    "The major difference between Series and ndarray is that the data is arranged based on label in Series, when Series is operated on.\n",
    "\n",
    "**A DataFrame is similar to a fixed-size dict because you can use the index labels to get and set values.**\n",
    "\n",
    "None of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bd997",
   "metadata": {},
   "source": [
    "**Q.Which function needs a dictionary of array like sequences or a dictionary of another dictionary, to return a DataFrame?**\n",
    "\n",
    "**DataFrame.from_items**\n",
    "\n",
    "DataFrame.from_records\n",
    "\n",
    "DataFrame.from_dict\n",
    "\n",
    "All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8765efc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a74cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
